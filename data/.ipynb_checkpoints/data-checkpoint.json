{
    "course_info": {
        "course_name": "人工智能",
        "course_code": "",
        "experiment_type": {
            "basic_experiment": false,
            "professional_experiment": true,
            "comprehensive_experiment": false
        }
    },
    "experiment_details": {
        "experiment_project_name": "卷积神经网络图像预测",
        "experiment_date": {
            "year": "2024",
            "month": "6",
            "day": "02"
        },
        "experiment_location": "1号实验楼 103 室"
    },
    "student_info": {
        "student_class": "数据科学与大数据技术 专业 2141班",
        "student_college": "大数据与人工智能学院",
        "student_major": "数据科学与大数据技术",
        "instructor_name": "丁红",
        "student_name": "李杰林",
        "student_id": "211005404103",
        "student_grade": ""
    },
    "experiment_purpose_and_requirements": {
        "purpose": "掌握卷积神经网络的基本原理和结构。\n了解如何使用卷积神经网络进行图像分类任务。\n学习使用深度学习框架PyTorch构建和训练卷积神经网络。\n实现手写数字识别，并评估模型的性能。",
        "requirements": "了解卷积层、池化层和全连接层的功能和作用。\n熟悉MNIST数据集的特点和使用方法。\n能够编写代码实现一个简单的卷积神经网络。\n对模型的训练过程进行记录，并绘制训练损失和准确率曲线。\n对训练好的模型进行测试，分析并报告其在测试集上的表现。\n"
    },
    "experiment_principle_methods_steps": {
        "principle": "卷积神经网络是一种用于图像处理的深度学习模型。它通过卷积层提取图像中的局部特征，通过池化层缩减特征图的尺寸，最后通过全连接层进行分类。在手写数字识别任务中，CNN能够自动学习图像中的重要特征，从而实现高精度的分类。",
        "methods": "数据预处理：加载MNIST手写数字数据集，并对图像数据进行归一化处理。\n构建模型：设计一个包含卷积层、池化层和全连接层的卷积神经网络。\n模型训练：使用训练数据训练模型，并记录训练过程中的损失和准确率。\n模型评估：使用测试数据评估模型性能，计算测试集上的准确率。",
        "steps": "导入和预处理数据：加载MNIST数据集，并将图像像素值归一化到[0, 1]范围。\n将数据集尺寸调整为残差网络的标准输入格式。\n设计卷积神经网络模型：引入残差网络，在适当的位置加上ca注意力机制。\n训练模型：使用训练数据进行模型训练，并在训练过程中监控损失和准确率。\n评估模型：使用测试数据集评估模型的准确率，分析模型的性能。"
    },
    "experiment_content_and_data": {
        "content": "import os\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchsummary import summary\nfrom tqdm import tqdm\nfrom PIL import Image\nimport csv\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n这段代码首先导入了所需的Python库，然后检查CUDA是否可用，并将设备设置为CUDA（如果可用）或CPU。CUDA是NVIDIA提供的并行计算平台和编程模型，允许在NVIDIA GPU上运行深度学习模型，从而加速计算过程。\n\n# 定义数据增强和预处理\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5]),  \n])\n\n这段代码定义了一系列图像预处理和增强操作，以便在训练模型时对图像数据进行处理。首先将进行随机水平翻转图像，将图像转换为张量，并最后对图像进行标准化处理，以便模型更好地学习和泛化。\n\nclass CA_Block(nn.Module):\n    def __init__(self, channel, h, w, reduction=16):\n        super(CA_Block, self).__init__()\n        self.h = h\n        self.w = w\n        self.avg_pool_x = nn.AdaptiveAvgPool2d((h, 1))\n        self.avg_pool_y = nn.AdaptiveAvgPool2d((1, w))\n        self.conv_1x1 = nn.Conv2d(in_channels=channel, out_channels=channel//reduction, kernel_size=1, stride=1, bias=False)\n        self.relu = nn.ReLU()\n        self.bn = nn.BatchNorm2d(channel//reduction)\n        self.F_h = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)\n        self.F_w = nn.Conv2d(in_channels=channel//reduction, out_channels=channel, kernel_size=1, stride=1, bias=False)\n        self.sigmoid_h = nn.Sigmoid()\n        self.sigmoid_w = nn.Sigmoid()\n    def forward(self, x):\n        x_h = self.avg_pool_x(x).permute(0, 1, 3, 2)\n        x_w = self.avg_pool_y(x)\n        x_cat_conv_relu = self.relu(self.conv_1x1(torch.cat((x_h, x_w), 3)))\n        x_cat_conv_split_h, x_cat_conv_split_w = x_cat_conv_relu.split([self.h, self.w], 3)\n        s_h = self.sigmoid_h(self.F_h(x_cat_conv_split_h.permute(0, 1, 3, 2)))\n        s_w = self.sigmoid_w(self.F_w(x_cat_conv_split_w))\n        out = x * s_h.expand_as(x) * s_w.expand_as(x)\n        return out\n        \n这个类定义了一个通道注意力块，用于在输入特征图的不同通道上加权重要性，以提高模型的性能。它首先对输入特征图在水平和垂直方向上进行平均池化，然后通过一系列卷积和激活函数操作生成通道注意力权重，最后将这些权重应用于输入特征图，得到加权后的输出特征图。\n\nclass CACNN(nn.Module):\n    def __init__(self):\n        super(CACNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.ca = CA_Block(channel=64, h=7, w=7)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = self.ca(x)\n        x = x.view(-1, 64 * 7 * 7)\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ncacnn = CACNN()\n\n这个类是一个简单的卷积神经网络模型，用于图像分类任务。它包含了卷积层、批归一化、ReLU激活函数、最大池化层、通道注意力模块和全连接层。模型接受图像作为输入，在每个层级中进行特征提取和变换，最终输出图像的类别预测结果。\n\nsummary(cacnn,input_size=(1,28,28),device='cpu')\n\n这行代码调用了PyTorch的summary函数来打印模型的摘要信息，包括模型结构、参数数量等。参数包括cacnn作为要分析的模型对象，input_size指定了输入数据的尺寸（1通道、28*28像素），device指定了在CPU上进行模型分析，再此我主要用于研究模型与注意力机制的有机融合，调整模型尺寸。\n\ndef evaluate(model, data_loader, criterion, device):\n    model.eval()  # 设置模型为评估模式\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():  # 关闭梯度计算\n        for images, labels in data_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    loss = running_loss / len(data_loader.dataset)\n    acc = correct / total\n    \n    return loss, acc\n\ndef train(model, train_loader, val_loader, criterion, optimizer, device, epochs=10, logs='./logs/training_log.csv',save_model=False):\n    os.makedirs(os.path.dirname(logs), exist_ok=True)\n    with open(logs, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Epoch', 'Train Loss', 'Train Acc', 'Val Loss', 'Val Acc'])\n\n    best_val_acc = 0.0  # 初始化最佳验证准确率\n    total_steps = epochs  # 每个epoch更新一次进度条\n    progress_bar = tqdm(total=total_steps, desc=\"Training Progress\")\n\n    for epoch in range(epochs):\n        model.train()  # 设置模型为训练模式\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()  # 梯度清零\n            outputs = model(images)  # 前向传播\n            loss = criterion(outputs, labels)  # 计算损失\n            loss.backward()  # 反向传播\n            optimizer.step()  # 更新权重\n            \n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        # 每个epoch更新一次进度条\n        progress_bar.update(1)\n        \n        train_loss = running_loss / len(train_loader.dataset)\n        train_acc = correct / total\n        \n        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n        \n        # 记录训练和验证日志信息到CSV文件\n        with open(logs, mode='a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([epoch + 1, train_loss, train_acc, val_loss, val_acc])\n        \n        # 如果当前验证准确率高于历史最高值，保存模型\n        if save_model == True:\n            os.makedirs(os.path.dirname('./model'), exist_ok=True)\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model, 'model/best_model.pth')  \n\n            torch.save(model, 'model/last_model.pth')  \n    \n    progress_bar.close()\n    \nevaluate(model, data_loader, criterion, device): 这个函数用于在给定数据集上评估模型的性能。它接受模型、数据加载器、损失函数和设备作为输入，并返回平均损失和准确率。\n\ntrain(model, train_loader, val_loader, criterion, optimizer, device, epochs=10, logs='./logs/training_log.csv',save_model=False): 这个函数用于训练模型。它接受模型、训练数据加载器、验证数据加载器、损失函数、优化器、设备和训练周期等参数。在每个周期中，它会迭代训练数据加载器，计算损失并执行反向传播来更新模型的权重。然后，它会在验证数据集上评估模型的性能，并记录训练和验证指标到CSV文件中。如果save_model参数设置为True，则在训练过程中保存最佳模型和最后一个模型。\n\n# 加载训练和验证数据集\ntrain_dataset = datasets.MNIST(root='./dataset/minst', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n\nval_dataset = datasets.MNIST(root='./dataset/minst',train=False,download=True,transform=transform)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)\n\n这段代码加载了MNIST数据集，包括训练集和验证集，并创建了对应的数据加载器。\n\n# 定义损失函数、优化器和设备\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(cacnn.parameters(), lr=0.001)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n这段代码简单地定义了模型的损失函数为交叉熵损失（用于多类别分类任务），优化器为Adam优化器（用于更新模型参数），学习率为0.001。同时，它检查CUDA是否可用，如果可用则将设备设置为GPU，否则设置为CPU。\n\n# 训练模型\ntrain(cacnn.to(device), train_loader, val_loader, criterion, optimizer, device, epochs=20,save_model=True)\n\n这段代码调用了之前定义的train函数来训练模型。它传入了模型（将其移动到设备上）、训练数据加载器、验证数据加载器、损失函数、优化器、设备和训练周期等参数。在训练过程中，模型将根据训练数据进行反向传播和参数更新，并在验证数据上评估模型性能。如果save_model参数设置为True，训练过程中会保存最佳模型和最后一个模型。\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 从 CSV 文件加载数据\ntraining_log = pd.read_csv('./logs/training_log.csv')\n\n# 创建图表\nfig, axes = plt.subplots(2, 1, figsize=(10, 12))\n\n# 绘制损失曲线\nsns.lineplot(data=training_log, x='Epoch', y='Train Loss', label='Train Loss', ax=axes[0])\nsns.lineplot(data=training_log, x='Epoch', y='Val Loss', label='Val Loss', ax=axes[0])\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training and Validation Loss Over Epochs')\naxes[0].legend()\n\n# 绘制准确率曲线\nsns.lineplot(data=training_log, x='Epoch', y='Train Acc', label='Train Acc', ax=axes[1])\nsns.lineplot(data=training_log, x='Epoch', y='Val Acc', label='Val Acc', ax=axes[1])\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].set_title('Training and Validation Accuracy Over Epochs')\naxes[1].legend()\n\n# 调整子图之间的间距\nplt.tight_layout()\n\n# 显示图表\nplt.show()\n\n这段代码将前面训练保存的日志文件进行可视化，绘制子图对比训练和评估的效果\n\n",
        "results": "我们由日志于可视化图可以看出，我们的模型在训练的过程中有较好的拟合效果，且模型仍有拟合能力，但拟合跨步不大，我们在下次训练可以尝试提高训练轮次、减小学习率、提高batch_size,以达到更好的效果。\n虽然我们本次实验模型性能并不优势于简单cnn模型，但是此模型我认为在日后更复杂的数据集上能有更优的表现。"
    },
    "experiment_reflection": {
        "experience": "通过本次实验，我们成功地完成了手写数字识别任务，并对卷积神经网络（CNN）的基本原理、结构和使用方法有了更深入的了解。以下是我们得出的一些结论和体会：\n卷积神经网络的基本原理和结构： 在实验中，我们深入学习了卷积层、池化层和全连接层的功能和作用。通过这些层的组合，CNN能够有效地提取图像中的局部特征，并实现图像分类等任务。\n深度学习框架PyTorch的应用： 实验中我们使用了PyTorch作为深度学习框架，利用其提供的模块和函数来构建、训练和评估卷积神经网络模型。PyTorch提供了灵活且强大的工具，使得我们能够更加高效地进行模型开发和实验。\n手写数字识别模型的性能评估： 我们在训练过程中监测了模型的损失和准确率，并通过测试集对训练好的模型进行了性能评估。通过评估结果，我们可以得知模型在测试集上的准确率，进而分析模型的性能和泛化能力。\n通道注意力机制在模型中的应用： 我们实现了一个结合了ResNet和通道注意力机制的神经网络模型。通过在ResNet的基础上引入通道注意力块，我们尝试提高模型对图像特征的关注度，从而进一步提升模型的性能。\n实验过程中的挑战和收获： 在实验过程中，我们遇到了一些挑战，如模型训练过程中的调参和性能优化，以及对PyTorch模块和函数的理解和熟悉等。通过克服这些挑战，我们不仅获得了手写数字识别模型的训练和评估经验，还加深了对卷积神经网络和深度学习框架的理解。\n综上所述，本次实验不仅帮助我们掌握了卷积神经网络的基本原理和结构，还提升了我们在深度学习领域的实践能力和经验积累。通过不断地实践和探索，我们将能够更好地应用深度学习技术解决实际问题，并不断提升自己在人工智能领域的能力和水平。\n"
    },
    "signatures": {
        "student_signature": "李杰林",
        "date": {
            "year": "2024",
            "month": "6",
            "day": "02"
        }
    }
}